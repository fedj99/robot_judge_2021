{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW07: Deep Learning (due 16th November)\n",
    "\n",
    "In this homework, you will replicate the heterogenous treatment effect exercise from last week's homework using a deep learning model instead of a machine learning one.\n",
    "\n",
    "For those who did not complete this exercise, you will investigate the effect of case management on mental health outcomes. These data come from a randomized control trial where patients were assigned to _intensive_ or _standard_ case management. In this context, the treatment is being assigned to the **intensive** case management while patients assigned to the **standard** case management belong to the control group.\n",
    "\n",
    "We will investigate characteristics of individuals who are most and least responsive to the treatment, i.e., to being assigned to the intensive case management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trialid': 'Trial ID',\n",
       " 'centreid': 'Trial centre',\n",
       " 'status': 'Patient status at baseline',\n",
       " 'age': 'Age in years at baseline',\n",
       " 'sex': 'Sex',\n",
       " 'afcarib': 'Ethnic group',\n",
       " 'ocfabth': \"Father's social class at birth\",\n",
       " 'chron1l': 'Months since onset of psychosis, logged',\n",
       " 'hos94': 'Days in hospital for psychiatric reasons: 2 years before baseline',\n",
       " 'cprs94': 'Psychopathology at baseline (CPRS)',\n",
       " 'das94': 'Disability at baseline (DAS)',\n",
       " 'sat94': '(Dis)satisfaction with services at baseline',\n",
       " 'rand': 'Randomised group',\n",
       " 'hos96': 'Days in hospital for psychiatric reasons: 2 years after baseline',\n",
       " 'cprs96': 'Psychopathology at 2 years (CPRS)',\n",
       " 'sat96': '(Dis)satisfaction with services at 2 years'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df = pd.read_stata(\n",
    "    'http://www.homepages.ucl.ac.uk/~rmjwiww/stata/missing/uk500.dta')\n",
    "df = df.dropna()\n",
    "pd.read_stata('http://www.homepages.ucl.ac.uk/~rmjwiww/stata/missing/uk500.dta',\n",
    "              iterator=True).variable_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialid</th>\n",
       "      <th>centreid</th>\n",
       "      <th>status</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>afcarib</th>\n",
       "      <th>ocfabth</th>\n",
       "      <th>chron1l</th>\n",
       "      <th>hos94</th>\n",
       "      <th>cprs94</th>\n",
       "      <th>das94</th>\n",
       "      <th>sat94</th>\n",
       "      <th>rand</th>\n",
       "      <th>hos96</th>\n",
       "      <th>cprs96</th>\n",
       "      <th>sat96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.0</td>\n",
       "      <td>St George's</td>\n",
       "      <td>Out-patient</td>\n",
       "      <td>27.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Other</td>\n",
       "      <td>A</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Intensive case management</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222005.0</td>\n",
       "      <td>St Mary's</td>\n",
       "      <td>In hospital</td>\n",
       "      <td>41.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Other</td>\n",
       "      <td>D</td>\n",
       "      <td>4.521789</td>\n",
       "      <td>240.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Intensive case management</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222018.0</td>\n",
       "      <td>St Mary's</td>\n",
       "      <td>In hospital</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Other</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>48.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Intensive case management</td>\n",
       "      <td>263.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>312015.0</td>\n",
       "      <td>King's</td>\n",
       "      <td>Out-patient</td>\n",
       "      <td>31.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Other</td>\n",
       "      <td>A</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>60.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Intensive case management</td>\n",
       "      <td>45.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>221023.0</td>\n",
       "      <td>St Mary's</td>\n",
       "      <td>In hospital</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Afro-Caribbean</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.571428</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Intensive case management</td>\n",
       "      <td>58.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trialid     centreid       status   age     sex         afcarib ocfabth  \\\n",
       "1     107.0  St George's  Out-patient  27.0    male           Other       A   \n",
       "2  222005.0    St Mary's  In hospital  41.0    male           Other       D   \n",
       "3  222018.0    St Mary's  In hospital  25.0    male           Other      C2   \n",
       "5  312015.0       King's  Out-patient  31.0  female           Other       A   \n",
       "6  221023.0    St Mary's  In hospital  35.0    male  Afro-Caribbean      C2   \n",
       "\n",
       "    chron1l  hos94  cprs94     das94  sat94                       rand  hos96  \\\n",
       "1  3.178054   80.0     4.0  0.285714   18.0  Intensive case management   27.0   \n",
       "2  4.521789  240.0     6.0  0.750000   15.0  Intensive case management   15.0   \n",
       "3  4.094345   48.0    12.0  0.125000   18.0  Intensive case management  263.0   \n",
       "5  4.787492   60.0    28.0  2.375000   20.0  Intensive case management   45.0   \n",
       "6  4.430817   60.0    25.0  1.571428   24.0  Intensive case management   58.0   \n",
       "\n",
       "   cprs96   sat96  \n",
       "1     3.0  22.000  \n",
       "2    13.0   9.000  \n",
       "3     6.0  21.375  \n",
       "5    19.0  17.000  \n",
       "6    27.0  19.125  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The treatment variable is $rand$, the post-treatment outcomes are $hos96$, $cprs96$ and $sat96$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intensive case management    130\n",
       "Standard case management     116\n",
       "Name: rand, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatvar = 'rand'\n",
    "df[treatvar].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat96</th>\n",
       "      <th>hos96</th>\n",
       "      <th>cprs96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>246.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.271341</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>17.790587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.723009</td>\n",
       "      <td>104.046722</td>\n",
       "      <td>14.090911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.187500</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>692.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sat96       hos96      cprs96\n",
       "count  246.000000  246.000000  246.000000\n",
       "mean    17.271341   65.500000   17.790587\n",
       "std      4.723009  104.046722   14.090911\n",
       "min      9.000000    0.000000    0.000000\n",
       "25%     14.000000    0.000000    7.000000\n",
       "50%     17.000000   15.000000   15.000000\n",
       "75%     20.187500   93.500000   26.000000\n",
       "max     32.000000  692.000000   71.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = ['sat96', 'hos96', 'cprs96']\n",
    "df[outcomes].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these variables we need a set of covariates that we want to use to identify individuals who are most and least responsive to treatment. We also encode categorical covariates and prepare them for the ML model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>sat94</th>\n",
       "      <th>ocfabth</th>\n",
       "      <th>hos94</th>\n",
       "      <th>das94</th>\n",
       "      <th>cprs94</th>\n",
       "      <th>age</th>\n",
       "      <th>afcarib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.571428</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status  sex  sat94  ocfabth  hos94     das94  cprs94   age  afcarib\n",
       "1     1.0  1.0   18.0      0.0   80.0  0.285714     4.0  27.0      1.0\n",
       "2     0.0  1.0   15.0      4.0  240.0  0.750000     6.0  41.0      1.0\n",
       "3     0.0  1.0   18.0      3.0   48.0  0.125000    12.0  25.0      1.0\n",
       "5     1.0  0.0   20.0      0.0   60.0  2.375000    28.0  31.0      1.0\n",
       "6     0.0  1.0   24.0      3.0   60.0  1.571428    25.0  35.0      0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding Categorical covariates and preparing the data for tensorflow\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "covariates = ['status', 'sex', 'sat94', 'ocfabth',\n",
    "              'hos94', 'das94', 'cprs94', 'age', 'afcarib']\n",
    "covariates_cat = ['status', 'sex', 'ocfabth', 'afcarib']\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "df[covariates_cat] = encoder.fit_transform(df[covariates_cat])\n",
    "df[covariates] = df[covariates].astype('float32')\n",
    "df[covariates].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status     float32\n",
       "sex        float32\n",
       "sat94      float32\n",
       "ocfabth    float32\n",
       "hos94      float32\n",
       "das94      float32\n",
       "cprs94     float32\n",
       "age        float32\n",
       "afcarib    float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset the dataset by treatment and control\n",
    "# Within each sample, create a training, a test and a validation set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_treat = df[df[treatvar] == 'Intensive case management']\n",
    "df_control = df[df[treatvar] == 'Standard case management']\n",
    "\n",
    "Xt = df_treat[covariates]\n",
    "Xc = df_control[covariates]\n",
    "yt = df_treat[outcomes]\n",
    "yc = df_control[outcomes]\n",
    "\n",
    "# 60/20/20 split\n",
    "Xt_train_val, Xt_test, yt_train_val, yt_test = train_test_split(\n",
    "    Xt, yt, test_size=0.2)\n",
    "Xc_train_val, Xc_test, yc_train_val, yc_test = train_test_split(\n",
    "    Xc, yc, test_size=0.2)\n",
    "Xt_train, Xt_val, yt_train, yt_val = train_test_split(\n",
    "    Xt_train_val, yt_train_val, test_size=0.2)\n",
    "Xc_train, Xc_val, yc_train, yc_val = train_test_split(\n",
    "    Xc_train_val, yc_train_val, test_size=0.2)\n",
    "\n",
    "Xt_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_260\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_790 (Dense)            (None, 31)                310       \n",
      "_________________________________________________________________\n",
      "batch_normalization_514 (Bat (None, 31)                124       \n",
      "_________________________________________________________________\n",
      "dropout_472 (Dropout)        (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "dense_791 (Dense)            (None, 17)                544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_515 (Bat (None, 17)                68        \n",
      "_________________________________________________________________\n",
      "dropout_473 (Dropout)        (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_792 (Dense)            (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 1,064\n",
      "Trainable params: 968\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 20ms/step - loss: 228.0163 - mse: 227.3685 - val_loss: 253.9025 - val_mse: 253.2354\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.3660 - mse: 89.6957 - val_loss: 40.2404 - val_mse: 39.5648\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.2240 - mse: 62.5399 - val_loss: 25.3068 - val_mse: 24.6203\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.3459 - mse: 54.6597 - val_loss: 37.4138 - val_mse: 36.7284\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.4574 - mse: 54.7726 - val_loss: 33.9956 - val_mse: 33.3118\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39.3726 - mse: 38.6892 - val_loss: 43.2386 - val_mse: 42.5556\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43.5885 - mse: 42.9061 - val_loss: 31.6501 - val_mse: 30.9685\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44.6343 - mse: 43.9531 - val_loss: 31.0764 - val_mse: 30.3948\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 42.8911 - mse: 42.2098 - val_loss: 30.1691 - val_mse: 29.4877\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38.8316 - mse: 38.1509 - val_loss: 28.6168 - val_mse: 27.9367\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40.6579 - mse: 39.9786 - val_loss: 28.4521 - val_mse: 27.7695\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33.4175 - mse: 32.7357 - val_loss: 27.1259 - val_mse: 26.4452\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 42.5707 - mse: 41.8908 - val_loss: 30.6220 - val_mse: 29.9433\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36.3884 - mse: 35.7105 - val_loss: 29.6268 - val_mse: 28.9500\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34.8285 - mse: 34.1521 - val_loss: 28.6040 - val_mse: 27.9285\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38.2347 - mse: 37.5599 - val_loss: 28.4559 - val_mse: 27.7822\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34.4964 - mse: 33.8235 - val_loss: 27.5485 - val_mse: 26.8767\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44.0050 - mse: 43.3336 - val_loss: 28.0696 - val_mse: 27.3992\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37.8498 - mse: 37.1790 - val_loss: 28.8585 - val_mse: 28.1882\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 42.3560 - mse: 41.6865 - val_loss: 28.2149 - val_mse: 27.5464\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37.3873 - mse: 36.7196 - val_loss: 28.1026 - val_mse: 27.4362\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44.0197 - mse: 43.3540 - val_loss: 29.4936 - val_mse: 28.8291\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 38.0330 - mse: 37.3693 - val_loss: 28.0908 - val_mse: 27.4283\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.7738 - mse: 33.1121 - val_loss: 31.2009 - val_mse: 30.5404\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33.0756 - mse: 32.4160 - val_loss: 30.1798 - val_mse: 29.5214\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35.4343 - mse: 34.7767 - val_loss: 30.0523 - val_mse: 29.3959\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 30.9758 - mse: 30.3202 - val_loss: 29.5871 - val_mse: 28.9327\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37.9759 - mse: 37.3223 - val_loss: 29.8029 - val_mse: 29.1502\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 31.7524 - mse: 31.1005 - val_loss: 28.7790 - val_mse: 28.1282\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 32.6554 - mse: 32.0048 - val_loss: 28.2417 - val_mse: 27.5920\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33.9806 - mse: 33.3317 - val_loss: 29.3335 - val_mse: 28.6855\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.1648 - mse: 29.5176 - val_loss: 27.9929 - val_mse: 27.3467\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.9279 - mse: 30.2823 - val_loss: 30.1323 - val_mse: 29.4877\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.4236 - mse: 29.7797 - val_loss: 30.2758 - val_mse: 29.6329\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.5355 - mse: 34.8934 - val_loss: 28.2076 - val_mse: 27.5664\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 26.8188 - mse: 26.1784 - val_loss: 30.6843 - val_mse: 30.0450\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.3240 - mse: 32.6855 - val_loss: 29.6016 - val_mse: 28.9643\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.7380 - mse: 33.1015 - val_loss: 28.4351 - val_mse: 27.7995\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.1203 - mse: 31.4856 - val_loss: 31.0852 - val_mse: 30.4517\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.9389 - mse: 34.3062 - val_loss: 28.0656 - val_mse: 27.4340\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 37.1190 - mse: 36.4881 - val_loss: 27.4936 - val_mse: 26.8638\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.4494 - mse: 27.8205 - val_loss: 28.5133 - val_mse: 27.8855\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.5720 - mse: 24.9450 - val_loss: 28.5824 - val_mse: 27.9566\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 39.5861 - mse: 38.9610 - val_loss: 29.3554 - val_mse: 28.7315\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.5024 - mse: 26.8793 - val_loss: 30.0832 - val_mse: 29.4613\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35.2764 - mse: 34.6552 - val_loss: 28.3710 - val_mse: 27.7509\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 26.1637 - mse: 25.5444 - val_loss: 28.9997 - val_mse: 28.3814\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.3421 - mse: 30.7245 - val_loss: 31.6464 - val_mse: 31.0298\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.7363 - mse: 33.1205 - val_loss: 28.9904 - val_mse: 28.3756\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.1536 - mse: 28.5396 - val_loss: 28.5730 - val_mse: 27.9601\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.6157 - mse: 30.0035 - val_loss: 28.7231 - val_mse: 28.1118\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.5135 - mse: 29.9030 - val_loss: 31.3923 - val_mse: 30.7829\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.0708 - mse: 29.4620 - val_loss: 30.0089 - val_mse: 29.4004\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.1587 - mse: 30.5507 - val_loss: 31.2789 - val_mse: 30.6710\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.6082 - mse: 29.0011 - val_loss: 28.5841 - val_mse: 27.9779\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.7256 - mse: 30.0884 - val_loss: 29.9293 - val_mse: 29.2575\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34.6910 - mse: 34.0200 - val_loss: 31.1693 - val_mse: 30.4995\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.0392 - mse: 30.3701 - val_loss: 28.6481 - val_mse: 27.9802\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.7369 - mse: 29.0698 - val_loss: 31.9865 - val_mse: 31.3206\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.3794 - mse: 28.7143 - val_loss: 32.0406 - val_mse: 31.3741\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.7150 - mse: 27.0490 - val_loss: 30.4822 - val_mse: 29.8168\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 30.6638 - mse: 29.9991 - val_loss: 28.8776 - val_mse: 28.2141\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.9459 - mse: 29.2831 - val_loss: 28.8510 - val_mse: 28.1893\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.8211 - mse: 29.1601 - val_loss: 29.5043 - val_mse: 28.8445\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 26.3672 - mse: 25.7081 - val_loss: 31.1788 - val_mse: 30.5206\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.4819 - mse: 28.8246 - val_loss: 29.0926 - val_mse: 28.4362\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.8582 - mse: 28.2026 - val_loss: 29.7421 - val_mse: 29.0876\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.4129 - mse: 27.7591 - val_loss: 29.1058 - val_mse: 28.4517\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.7641 - mse: 28.1107 - val_loss: 28.6116 - val_mse: 27.9593\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.2163 - mse: 31.5638 - val_loss: 28.7443 - val_mse: 28.0928\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.0989 - mse: 28.4480 - val_loss: 28.9398 - val_mse: 28.2899\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 29.5436 - mse: 28.8941 - val_loss: 28.5456 - val_mse: 27.8971\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 28.2598 - mse: 27.6121 - val_loss: 29.5299 - val_mse: 28.8833\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 19ms/step - loss: 216.2409 - mse: 215.3354 - val_loss: 404.6191 - val_mse: 403.6044\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 70.7409 - mse: 69.7175 - val_loss: 103.2388 - val_mse: 102.1993\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48.7921 - mse: 47.7478 - val_loss: 27.4345 - val_mse: 26.3890\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46.0205 - mse: 44.9745 - val_loss: 40.4551 - val_mse: 39.4093\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43.0675 - mse: 42.0217 - val_loss: 31.6242 - val_mse: 30.5796\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34.3782 - mse: 33.3344 - val_loss: 22.5754 - val_mse: 21.5328\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33.8902 - mse: 32.8482 - val_loss: 33.3777 - val_mse: 32.3357\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39.0822 - mse: 38.0414 - val_loss: 20.6220 - val_mse: 19.5831\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34.0029 - mse: 32.9651 - val_loss: 22.2492 - val_mse: 21.2132\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35.6199 - mse: 34.5851 - val_loss: 25.2821 - val_mse: 24.2491\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34.3152 - mse: 33.2827 - val_loss: 28.5985 - val_mse: 27.5676\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 30.6582 - mse: 29.6282 - val_loss: 24.3466 - val_mse: 23.3180\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 31.9312 - mse: 30.9036 - val_loss: 25.8608 - val_mse: 24.8351\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 25.0352 - mse: 24.0107 - val_loss: 32.1790 - val_mse: 31.1564\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 30.9315 - mse: 29.9101 - val_loss: 27.5514 - val_mse: 26.5319\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35.1606 - mse: 34.1424 - val_loss: 28.4842 - val_mse: 27.4677\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33.0115 - mse: 31.9962 - val_loss: 30.8352 - val_mse: 29.8218\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.2448 - mse: 21.2325 - val_loss: 24.7729 - val_mse: 23.7625\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.8177 - mse: 30.8086 - val_loss: 28.0580 - val_mse: 27.0508\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.5817 - mse: 31.5757 - val_loss: 74.0186 - val_mse: 73.0144\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 32.9668 - mse: 31.9639 - val_loss: 21.6778 - val_mse: 20.6767\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23.9093 - mse: 22.9094 - val_loss: 37.2093 - val_mse: 36.2111\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.1036 - mse: 26.1065 - val_loss: 31.9456 - val_mse: 30.9503\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.3687 - mse: 21.3746 - val_loss: 24.5909 - val_mse: 23.5987\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.5071 - mse: 26.5160 - val_loss: 21.5551 - val_mse: 20.5657\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 26.9318 - mse: 25.9436 - val_loss: 31.0115 - val_mse: 30.0231\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.8194 - mse: 26.8320 - val_loss: 33.1544 - val_mse: 32.1688\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.3468 - mse: 26.3622 - val_loss: 23.6437 - val_mse: 22.6596\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.9174 - mse: 30.9341 - val_loss: 23.1540 - val_mse: 21.3275\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.7626 - mse: 19.9384 - val_loss: 24.7286 - val_mse: 22.9079\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23.3205 - mse: 21.5021 - val_loss: 26.2075 - val_mse: 24.3925\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.5542 - mse: 18.7415 - val_loss: 32.7054 - val_mse: 30.8953\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.4837 - mse: 23.6759 - val_loss: 24.4784 - val_mse: 22.6741\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.2732 - mse: 16.4712 - val_loss: 25.4792 - val_mse: 23.6806\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.8145 - mse: 20.0181 - val_loss: 26.3460 - val_mse: 24.5530\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.9863 - mse: 20.1956 - val_loss: 26.9274 - val_mse: 25.1401\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.1918 - mse: 19.4068 - val_loss: 26.6279 - val_mse: 24.8463\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23.7310 - mse: 21.9516 - val_loss: 28.8311 - val_mse: 27.0550\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27.6957 - mse: 25.9218 - val_loss: 25.8843 - val_mse: 24.1139\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.7721 - mse: 21.0038 - val_loss: 24.7420 - val_mse: 22.9771\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.2726 - mse: 20.5099 - val_loss: 32.3077 - val_mse: 30.5484\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.0986 - mse: 20.3415 - val_loss: 26.4860 - val_mse: 24.7321\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 25.1668 - mse: 23.4150 - val_loss: 27.6847 - val_mse: 25.9363\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.1884 - mse: 17.4421 - val_loss: 23.1168 - val_mse: 21.3739\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20.9199 - mse: 19.1791 - val_loss: 23.1232 - val_mse: 21.3858\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.5821 - mse: 19.8468 - val_loss: 26.6169 - val_mse: 24.8846\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.9768 - mse: 21.2467 - val_loss: 31.8132 - val_mse: 30.0862\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.3723 - mse: 19.6475 - val_loss: 28.1730 - val_mse: 26.4515\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.7103 - mse: 18.9909 - val_loss: 23.9098 - val_mse: 22.1937\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.5457 - mse: 19.8317 - val_loss: 27.8653 - val_mse: 26.1547\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.4902 - mse: 20.7814 - val_loss: 30.6417 - val_mse: 28.9354\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.4415 - mse: 16.7372 - val_loss: 24.1864 - val_mse: 22.4853\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.8663 - mse: 17.1674 - val_loss: 27.9137 - val_mse: 26.2180\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.6774 - mse: 15.9838 - val_loss: 24.7200 - val_mse: 23.0292\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.1102 - mse: 18.4215 - val_loss: 27.8767 - val_mse: 26.1909\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.8964 - mse: 18.2128 - val_loss: 24.8438 - val_mse: 23.1633\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.4774 - mse: 18.7990 - val_loss: 24.1966 - val_mse: 22.5214\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.0887 - mse: 18.4155 - val_loss: 26.3364 - val_mse: 24.6664\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.8750 - mse: 19.2070 - val_loss: 25.4322 - val_mse: 23.7664\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.8752 - mse: 15.2115 - val_loss: 26.5708 - val_mse: 24.9102\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.3929 - mse: 18.7344 - val_loss: 32.0492 - val_mse: 30.3939\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.5821 - mse: 17.9289 - val_loss: 26.0878 - val_mse: 24.4376\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.4197 - mse: 17.7715 - val_loss: 24.5800 - val_mse: 22.9349\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.1575 - mse: 17.5144 - val_loss: 29.9819 - val_mse: 28.3419\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.3917 - mse: 19.7538 - val_loss: 26.2906 - val_mse: 24.6558\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.7842 - mse: 20.1514 - val_loss: 33.5502 - val_mse: 31.9205\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.9898 - mse: 18.3621 - val_loss: 23.0601 - val_mse: 21.4355\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.6429 - mse: 17.0204 - val_loss: 24.2330 - val_mse: 22.6136\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.1420 - mse: 18.5246 - val_loss: 24.0801 - val_mse: 22.4658\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.9351 - mse: 15.3228 - val_loss: 24.4087 - val_mse: 22.7994\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 21.1151 - mse: 19.5079 - val_loss: 25.5471 - val_mse: 23.9429\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.3977 - mse: 17.7954 - val_loss: 25.4281 - val_mse: 23.8285\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.9062 - mse: 18.3085 - val_loss: 27.0447 - val_mse: 25.4499\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.2451 - mse: 18.6523 - val_loss: 24.3140 - val_mse: 22.7241\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.7096 - mse: 17.1217 - val_loss: 23.8008 - val_mse: 22.2158\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.4381 - mse: 17.8549 - val_loss: 23.4494 - val_mse: 21.8689\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.5827 - mse: 15.0041 - val_loss: 25.9431 - val_mse: 24.3666\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.2278 - mse: 16.6531 - val_loss: 22.8193 - val_mse: 21.2477\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.3832 - mse: 17.8133 - val_loss: 23.7795 - val_mse: 22.2126\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.9815 - mse: 15.4165 - val_loss: 27.7164 - val_mse: 26.1543\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.8791 - mse: 15.3189 - val_loss: 23.2210 - val_mse: 21.6637\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.2698 - mse: 14.7143 - val_loss: 24.1132 - val_mse: 22.5606\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.7696 - mse: 15.2188 - val_loss: 24.4501 - val_mse: 22.9022\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.0482 - mse: 17.5023 - val_loss: 25.0021 - val_mse: 23.4590\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.9364 - mse: 16.3952 - val_loss: 25.9456 - val_mse: 24.4071\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.4864 - mse: 15.9492 - val_loss: 25.3000 - val_mse: 23.7654\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 19.4983 - mse: 17.9656 - val_loss: 24.2744 - val_mse: 22.7446\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.3122 - mse: 16.7842 - val_loss: 23.6039 - val_mse: 22.0787\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.9836 - mse: 17.4602 - val_loss: 24.3760 - val_mse: 22.8554\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.5522 - mse: 15.0336 - val_loss: 24.5043 - val_mse: 22.9885\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.5245 - mse: 14.0107 - val_loss: 24.0490 - val_mse: 22.5380\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.4364 - mse: 14.9272 - val_loss: 24.2189 - val_mse: 22.7121\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.9607 - mse: 14.4555 - val_loss: 24.8157 - val_mse: 23.3131\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.0279 - mse: 15.5270 - val_loss: 22.6840 - val_mse: 21.1859\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.3536 - mse: 15.8572 - val_loss: 21.6221 - val_mse: 20.1286\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 20.3146 - mse: 18.8227 - val_loss: 23.0043 - val_mse: 21.5150\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 18.2671 - mse: 16.7794 - val_loss: 26.3260 - val_mse: 24.8395\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 16.6537 - mse: 15.1689 - val_loss: 30.9434 - val_mse: 29.4499\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 17.4632 - mse: 15.9715 - val_loss: 26.4209 - val_mse: 24.9321\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 15.5782 - mse: 14.0912 - val_loss: 26.8509 - val_mse: 25.3667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16f362bb0>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choose one of the three outcomes to analyze\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import initializers, regularizers\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "outcome = ['sat96']\n",
    "\n",
    "# build two MLP (multilayer perceptron) models to predict the outcome based on the covariates\n",
    "# the first model should be trained on the treated sample, while the second on the control\n",
    "\n",
    "# the two MLP models should have with at least 2 hidden layers, ReLU activation, batch normalization, dropout\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def construct(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(\n",
    "        31,\n",
    "        input_dim=input_dim,\n",
    "        activation='relu',\n",
    "        kernel_initializer='he_normal',\n",
    "        kernel_regularizer='l2'\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(17, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu', kernel_initializer='he_normal'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile(model: Sequential):\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='sgd',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "\n",
    "\n",
    "def fit(model: Sequential, X_train, y_train, X_val, y_val):\n",
    "    es = EarlyStopping(monitor='loss', patience=30)\n",
    "    return model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=100,\n",
    "        validation_data=(X_val, y_val),\n",
    "        steps_per_epoch=8,\n",
    "        callbacks=[es],\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "\n",
    "\n",
    "# Create models\n",
    "model_treat = construct(Xt.shape[1])\n",
    "model_control = construct(Xc.shape[1])\n",
    "\n",
    "model_treat.summary()\n",
    "\n",
    "# compile the models\n",
    "compile(model_treat)\n",
    "compile(model_control)\n",
    "\n",
    "# fit separate models on the treatment dataset and control dataset\n",
    "# use early stopping\n",
    "history_treat = fit(model_treat, Xt_train,\n",
    "                    yt_train[outcome], Xt_val, yt_val[outcome])\n",
    "history_control = fit(model_control, Xc_train,\n",
    "                      yc_train[outcome], Xc_val, yc_val[outcome])\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.plot(history_treat.epoch, history_treat.history['mse'])\n",
    "plt.plot(history_treat.epoch, history_treat.history['val_mse'])\n",
    "plt.plot(history_control.epoch, history_control.history['mse'])\n",
    "plt.plot(history_control.epoch, history_control.history['val_mse'])\n",
    "plt.legend(['Treat Train', 'Treat Val',\n",
    "           'Control Train', 'Control Val'], loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 70ms/step - loss: 3961.7590 - mse: 3961.7590 - val_loss: 4508.0249 - val_mse: 4508.0249\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3835.6431 - mse: 3835.6431 - val_loss: 3949.8230 - val_mse: 3949.8230\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3615.5181 - mse: 3615.5181 - val_loss: 3824.3308 - val_mse: 3824.3308\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3394.4880 - mse: 3394.4880 - val_loss: 3776.7690 - val_mse: 3776.7690\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3140.9941 - mse: 3140.9941 - val_loss: 3740.9163 - val_mse: 3740.9163\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3048.9099 - mse: 3048.9099 - val_loss: 3910.1965 - val_mse: 3910.1965\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3104.0884 - mse: 3104.0884 - val_loss: 4111.2275 - val_mse: 4111.2275\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3043.1042 - mse: 3043.1042 - val_loss: 3826.6760 - val_mse: 3826.6760\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3308.0383 - mse: 3308.0383 - val_loss: 3729.1206 - val_mse: 3729.1206\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3058.6914 - mse: 3058.6914 - val_loss: 3745.5691 - val_mse: 3745.5691\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3162.6667 - mse: 3162.6667 - val_loss: 3751.5874 - val_mse: 3751.5874\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3246.6089 - mse: 3246.6089 - val_loss: 240438080.0000 - val_mse: 240438080.0000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3190.6577 - mse: 3190.6577 - val_loss: 3753.6917 - val_mse: 3753.6917\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3064.7344 - mse: 3064.7344 - val_loss: 3882.4402 - val_mse: 3882.4402\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3084.1958 - mse: 3084.1958 - val_loss: 4315.1582 - val_mse: 4315.1582\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3341.8696 - mse: 3341.8696 - val_loss: 3849.5247 - val_mse: 3849.5247\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3160.2627 - mse: 3160.2627 - val_loss: 3947.1926 - val_mse: 3947.1926\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3133.4189 - mse: 3133.4189 - val_loss: 3879.8965 - val_mse: 3879.8965\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3180.7915 - mse: 3180.7915 - val_loss: 3792.7239 - val_mse: 3792.7239\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3100.6729 - mse: 3100.6729 - val_loss: 3754.5640 - val_mse: 3754.5640\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3188.3772 - mse: 3188.3772 - val_loss: 3770.5261 - val_mse: 3770.5261\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3088.5945 - mse: 3088.5945 - val_loss: 3752.0964 - val_mse: 3752.0964\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3172.6853 - mse: 3172.6853 - val_loss: 3771.1597 - val_mse: 3771.1597\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3062.7297 - mse: 3062.7297 - val_loss: 3770.4695 - val_mse: 3770.4695\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3143.9128 - mse: 3143.9128 - val_loss: 3795.5591 - val_mse: 3795.5591\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3158.5945 - mse: 3158.5945 - val_loss: 3791.2712 - val_mse: 3791.2712\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3188.2241 - mse: 3188.2241 - val_loss: 3783.9119 - val_mse: 3783.9119\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3174.7258 - mse: 3174.7258 - val_loss: 3778.7756 - val_mse: 3778.7756\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3142.0925 - mse: 3142.0925 - val_loss: 3763.4275 - val_mse: 3763.4275\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3140.2876 - mse: 3140.2876 - val_loss: 3757.3464 - val_mse: 3757.3464\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3082.6875 - mse: 3082.6875 - val_loss: 3823.8865 - val_mse: 3823.8865\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3086.7266 - mse: 3086.7266 - val_loss: 3797.4502 - val_mse: 3797.4502\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3145.8262 - mse: 3145.8262 - val_loss: 3770.3389 - val_mse: 3770.3389\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3111.9929 - mse: 3111.9929 - val_loss: 3827.5605 - val_mse: 3827.5605\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3175.2639 - mse: 3175.2639 - val_loss: 3761.6604 - val_mse: 3761.6604\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3054.2581 - mse: 3054.2581 - val_loss: 4298.3149 - val_mse: 4298.3149\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3074.7693 - mse: 3074.7693 - val_loss: 3764.5332 - val_mse: 3764.5332\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2994.9314 - mse: 2994.9314 - val_loss: 3792.7202 - val_mse: 3792.7202\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3085.2554 - mse: 3085.2554 - val_loss: 3739.2913 - val_mse: 3739.2913\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3168.2312 - mse: 3168.2312 - val_loss: 3744.8137 - val_mse: 3744.8137\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3133.1091 - mse: 3133.1091 - val_loss: 3736.4048 - val_mse: 3736.4048\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3064.1306 - mse: 3064.1306 - val_loss: 3740.1436 - val_mse: 3740.1436\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3165.2556 - mse: 3165.2556 - val_loss: 3707.9902 - val_mse: 3707.9902\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3061.7175 - mse: 3061.7175 - val_loss: 3707.3337 - val_mse: 3707.3337\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3151.0454 - mse: 3151.0454 - val_loss: 3710.1697 - val_mse: 3710.1697\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3090.2393 - mse: 3090.2393 - val_loss: 3716.4402 - val_mse: 3716.4402\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3151.0359 - mse: 3151.0359 - val_loss: 3718.6904 - val_mse: 3718.6904\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3120.8599 - mse: 3120.8599 - val_loss: 3716.8054 - val_mse: 3716.8054\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3137.7805 - mse: 3137.7805 - val_loss: 3720.6897 - val_mse: 3720.6897\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3084.2986 - mse: 3084.2988 - val_loss: 3747.5986 - val_mse: 3747.5986\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7948.4722 - mse: 7948.4722\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 64ms/step - loss: 5392.2510 - mse: 5392.2510 - val_loss: 2786.8491 - val_mse: 2786.8491\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 5236.5508 - mse: 5236.5508 - val_loss: 44988.6992 - val_mse: 44988.6992\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4923.0923 - mse: 4923.0923 - val_loss: 13274078.0000 - val_mse: 13274078.0000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4679.3643 - mse: 4679.3643 - val_loss: 295221.0625 - val_mse: 295221.0625\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4665.5137 - mse: 4665.5137 - val_loss: 46778.6172 - val_mse: 46778.6172\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4501.4272 - mse: 4501.4272 - val_loss: 2859.8264 - val_mse: 2859.8264\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4508.1333 - mse: 4508.1333 - val_loss: 2661.0383 - val_mse: 2661.0383\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4539.0679 - mse: 4539.0679 - val_loss: 4991.2197 - val_mse: 4991.2197\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4459.7725 - mse: 4459.7725 - val_loss: 3572.8667 - val_mse: 3572.8667\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4656.1338 - mse: 4656.1338 - val_loss: 2801.7424 - val_mse: 2801.7424\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4405.8979 - mse: 4405.8979 - val_loss: 2639.1426 - val_mse: 2639.1426\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4395.7881 - mse: 4395.7881 - val_loss: 6845.4219 - val_mse: 6845.4219\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4584.1021 - mse: 4584.1021 - val_loss: 2640.0156 - val_mse: 2640.0156\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4590.3867 - mse: 4590.3867 - val_loss: 2958.3640 - val_mse: 2958.3640\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4546.4980 - mse: 4546.4980 - val_loss: 2815.2229 - val_mse: 2815.2229\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4548.4546 - mse: 4548.4546 - val_loss: 3147.8914 - val_mse: 3147.8914\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4498.6714 - mse: 4498.6714 - val_loss: 3021.9941 - val_mse: 3021.9941\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4355.1621 - mse: 4355.1621 - val_loss: 2914.2903 - val_mse: 2914.2903\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4491.9419 - mse: 4491.9419 - val_loss: 2807.5359 - val_mse: 2807.5359\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4557.2847 - mse: 4557.2847 - val_loss: 2785.1184 - val_mse: 2785.1184\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4536.0435 - mse: 4536.0435 - val_loss: 2761.6184 - val_mse: 2761.6184\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4420.2456 - mse: 4420.2456 - val_loss: 2750.3582 - val_mse: 2750.3582\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4388.6445 - mse: 4388.6445 - val_loss: 2811.4463 - val_mse: 2811.4463\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4367.0273 - mse: 4367.0273 - val_loss: 2820.2129 - val_mse: 2820.2129\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4451.4463 - mse: 4451.4463 - val_loss: 2890.1506 - val_mse: 2890.1506\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4515.1157 - mse: 4515.1157 - val_loss: 2751.5027 - val_mse: 2751.5027\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4385.3696 - mse: 4385.3696 - val_loss: 3003.1875 - val_mse: 3003.1875\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4482.1392 - mse: 4482.1392 - val_loss: 3050.6628 - val_mse: 3050.6628\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4482.2031 - mse: 4482.2031 - val_loss: 2948.5454 - val_mse: 2948.5454\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4482.6270 - mse: 4482.6270 - val_loss: 2780.7974 - val_mse: 2780.7974\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4428.3447 - mse: 4428.3447 - val_loss: 2870.3474 - val_mse: 2870.3474\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4456.7036 - mse: 4456.7036 - val_loss: 2786.8088 - val_mse: 2786.8088\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4558.1929 - mse: 4558.1929 - val_loss: 2933.8574 - val_mse: 2933.8574\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4421.3730 - mse: 4421.3730 - val_loss: 2961.2468 - val_mse: 2961.2468\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4391.1084 - mse: 4391.1084 - val_loss: 2981.3625 - val_mse: 2981.3625\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4521.5405 - mse: 4521.5405 - val_loss: 2872.1064 - val_mse: 2872.1064\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4500.2725 - mse: 4500.2725 - val_loss: 2860.9434 - val_mse: 2860.9434\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4457.1509 - mse: 4457.1509 - val_loss: 2896.5598 - val_mse: 2896.5598\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4436.4941 - mse: 4436.4941 - val_loss: 2881.5823 - val_mse: 2881.5823\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4385.1875 - mse: 4385.1875 - val_loss: 2894.2170 - val_mse: 2894.2170\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4517.3354 - mse: 4517.3354 - val_loss: 2941.3154 - val_mse: 2941.3154\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4519.4775 - mse: 4519.4775 - val_loss: 2786.7637 - val_mse: 2786.7637\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4376.8833 - mse: 4376.8833 - val_loss: 2819.0491 - val_mse: 2819.0491\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4351.2100 - mse: 4351.2100 - val_loss: 2691.9849 - val_mse: 2691.9849\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4586.2993 - mse: 4586.2993 - val_loss: 2721.8337 - val_mse: 2721.8337\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4416.8418 - mse: 4416.8418 - val_loss: 2728.3813 - val_mse: 2728.3813\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4379.9531 - mse: 4379.9531 - val_loss: 2759.6692 - val_mse: 2759.6692\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4345.1782 - mse: 4345.1782 - val_loss: 2791.8667 - val_mse: 2791.8667\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4460.5649 - mse: 4460.5649 - val_loss: 2870.1626 - val_mse: 2870.1626\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4380.5532 - mse: 4380.5532 - val_loss: 2748.2366 - val_mse: 2748.2366\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4160.2935 - mse: 4160.2935\n",
      "-7948.47216796875 -4160.29345703125\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_dim=Xt_train.shape[1], n_hidden=2, n_neurons=30, learning_rate=3e-3, batch_normalization=True, dropout=True, dropout_rate=.5):\n",
    "    # Sequential model\n",
    "    model = Sequential()\n",
    "    # Input layer\n",
    "    model.add(Dense(n_neurons, input_dim=input_dim, activation='relu'))\n",
    "    # Hidden layers\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation='relu'))\n",
    "        if batch_normalization:\n",
    "            model.add(BatchNormalization())\n",
    "        if dropout:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "    optimizer= keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_pred(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "    keras_reg.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
    "    mse_test = keras_reg.score(X_test, y_test)\n",
    "    y_pred = keras_reg.predict(X_test)\n",
    "    return mse_test, y_pred\n",
    "\n",
    "\n",
    "mse_treat, yhat_treat = fit_pred(Xt_train, yt_train, Xt_val, yt_val, Xt_test, yt_test)\n",
    "mse_control, yhat_control = fit_pred(Xc_train, yc_train, Xc_val, yc_val, Xc_test, yc_test)\n",
    "\n",
    "print(mse_treat, mse_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Treatment Group 34.47403690946332\n",
      "MSE Control   Group 28.43568055300351\n"
     ]
    }
   ],
   "source": [
    "# get predicted outcomes using the combined test sets for both models\n",
    "\n",
    "test_set = Xt_test.append(Xc_test)\n",
    "yhat_treat = model_treat.predict(test_set)\n",
    "yhat_control = model_control.predict(test_set)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_test = yt_test[outcome].append(yc_test[outcome])\n",
    "print(\"MSE Treatment Group\", mean_squared_error(y_test, yhat_treat))\n",
    "print(\"MSE Control   Group\", mean_squared_error(y_test, yhat_control))\n",
    "\n",
    "# I really don't know why it's this bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>sat94</th>\n",
       "      <th>ocfabth</th>\n",
       "      <th>hos94</th>\n",
       "      <th>das94</th>\n",
       "      <th>cprs94</th>\n",
       "      <th>age</th>\n",
       "      <th>afcarib</th>\n",
       "      <th>treat_effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.844763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.097727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.759014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     status  sex  sat94  ocfabth  hos94     das94  cprs94   age  afcarib  \\\n",
       "7       1.0  0.0   20.0      3.0  730.0  0.400000    14.0  60.0      1.0   \n",
       "299     1.0  1.0   22.0      3.0    4.0  0.500000    11.0  30.0      1.0   \n",
       "466     1.0  1.0   19.0      3.0  331.0  0.142857     9.0  26.0      1.0   \n",
       "\n",
       "     treat_effect  \n",
       "7        3.844763  \n",
       "299      2.097727  \n",
       "466      1.759014  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the three individuals in the test set that are most and least responsive to the treatment\n",
    "# namely the three individuals for who the treatment effect is larger and those for who it is smaller\n",
    "\n",
    "test_set['treat_effect'] = yhat_treat - yhat_control\n",
    "test_set.sort_values('treat_effect',ascending=False).head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize and comment on the covariates of these individuals\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
